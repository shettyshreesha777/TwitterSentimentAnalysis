{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a57840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5083333333333335\n",
      "Amount of Positive tweets: 3.0\n",
      "Amount of Negative tweets: 4.0\n",
      "Amount of Neutral tweets: 7.0\n",
      "['negative', 'neutral', 'positive']\n",
      "               User                                              Tweet  \\\n",
      "0      ShalaSalazar   #twittersold costs musk $44 billion to feed h...   \n",
      "1      techranger58   #twittersold costs musk $44 billion to feed h...   \n",
      "2      notminenoway   #twittersold costs musk $44 billion to feed h...   \n",
      "3   unknown36852175   i hope that even my worst critics remain on t...   \n",
      "4         chuck8708   amazon added to cartüòÇ\\n#elonmuskbuytwitter #e...   \n",
      "5         mcbuncart   after #twittersold for $44 billion to elon mu...   \n",
      "6        sararosenm     i think might start‚Ä¶. tweeting. ü´£ #twittersold   \n",
      "7      urbanmowgli_                         bahot paisaü•π#twittersold     \n",
      "8        K_h_a_n___   ·µá·µâ ·µñ·µÉ·µó‚Å±·µâ‚Åø·µó  ∑‚Å±·µó ∞  ∏·µí·µò ≥\\n  À°‚Å±·∂†·µâ ·µÉ‚Åø·µà  ∏·µí·µò ≥ ·µñ·µÉ·µó ∞.\\n...   \n",
      "9          K__h_a_n   ·µá·µâ ·µñ·µÉ·µó‚Å±·µâ‚Åø·µó  ∑‚Å±·µó ∞  ∏·µí·µò ≥\\n  À°‚Å±·∂†·µâ ·µÉ‚Åø·µà  ∏·µí·µò ≥ ·µñ·µÉ·µó ∞.\\n...   \n",
      "10        raj143ver   elon musk ki salary itni jaldi aagayi? üí∏\\n\\n#...   \n",
      "11           mkt4id  with someone as reasonable as you in charge, c...   \n",
      "12   dogeordie69420     taking over #twittersold #twitter and #pump...   \n",
      "13    NFTToasties69   dogecoin futur is bright! üöÄ #twittersold #dog...   \n",
      "\n",
      "       class  negative   neutral  positive  \n",
      "0   NEGATIVE  0.707986  0.273129  0.018885  \n",
      "1   NEGATIVE  0.707986  0.273129  0.018885  \n",
      "2   NEGATIVE  0.707986  0.273129  0.018885  \n",
      "3   NEGATIVE  0.119781  0.520989  0.359230  \n",
      "4    NEUTRAL  0.049197  0.567841  0.382962  \n",
      "5    NEUTRAL  0.534441  0.419001  0.046558  \n",
      "6    NEUTRAL  0.072978  0.740127  0.186894  \n",
      "7    NEUTRAL  0.127917  0.670773  0.201310  \n",
      "8    NEUTRAL  0.063275  0.864014  0.072712  \n",
      "9    NEUTRAL  0.063275  0.864014  0.072712  \n",
      "10   NEUTRAL  0.099986  0.766955  0.133059  \n",
      "11  POSITIVE  0.242612  0.576722  0.180666  \n",
      "12  POSITIVE  0.094545  0.645744  0.259711  \n",
      "13  POSITIVE  0.001688  0.057683  0.940629  \n",
      "               User                                              Tweet  \\\n",
      "0      ShalaSalazar   #twittersold costs musk $44 billion to feed h...   \n",
      "1      techranger58   #twittersold costs musk $44 billion to feed h...   \n",
      "2      notminenoway   #twittersold costs musk $44 billion to feed h...   \n",
      "3   unknown36852175   i hope that even my worst critics remain on t...   \n",
      "4         chuck8708   amazon added to cartüòÇ\\n#elonmuskbuytwitter #e...   \n",
      "5         mcbuncart   after #twittersold for $44 billion to elon mu...   \n",
      "6        sararosenm     i think might start‚Ä¶. tweeting. ü´£ #twittersold   \n",
      "7      urbanmowgli_                         bahot paisaü•π#twittersold     \n",
      "8        K_h_a_n___   ·µá·µâ ·µñ·µÉ·µó‚Å±·µâ‚Åø·µó  ∑‚Å±·µó ∞  ∏·µí·µò ≥\\n  À°‚Å±·∂†·µâ ·µÉ‚Åø·µà  ∏·µí·µò ≥ ·µñ·µÉ·µó ∞.\\n...   \n",
      "9          K__h_a_n   ·µá·µâ ·µñ·µÉ·µó‚Å±·µâ‚Åø·µó  ∑‚Å±·µó ∞  ∏·µí·µò ≥\\n  À°‚Å±·∂†·µâ ·µÉ‚Åø·µà  ∏·µí·µò ≥ ·µñ·µÉ·µó ∞.\\n...   \n",
      "10        raj143ver   elon musk ki salary itni jaldi aagayi? üí∏\\n\\n#...   \n",
      "11           mkt4id  with someone as reasonable as you in charge, c...   \n",
      "12   dogeordie69420     taking over #twittersold #twitter and #pump...   \n",
      "13    NFTToasties69   dogecoin futur is bright! üöÄ #twittersold #dog...   \n",
      "\n",
      "       class  negative   neutral  positive  polarity  subjectivity     anger  \\\n",
      "0   NEGATIVE  0.707986  0.273129  0.018885 -0.300000     -0.300000  0.631437   \n",
      "1   NEGATIVE  0.707986  0.273129  0.018885 -0.300000     -0.300000  0.631437   \n",
      "2   NEGATIVE  0.707986  0.273129  0.018885 -0.300000     -0.300000  0.631437   \n",
      "3   NEGATIVE  0.119781  0.520989  0.359230 -0.300000     -0.300000  0.089530   \n",
      "4    NEUTRAL  0.049197  0.567841  0.382962  0.000000      0.000000  0.100421   \n",
      "5    NEUTRAL  0.534441  0.419001  0.046558  0.000000      0.000000  0.094879   \n",
      "6    NEUTRAL  0.072978  0.740127  0.186894  0.000000      0.000000  0.044255   \n",
      "7    NEUTRAL  0.127917  0.670773  0.201310  0.000000      0.000000  0.022384   \n",
      "8    NEUTRAL  0.063275  0.864014  0.072712  0.000000      0.000000  0.063975   \n",
      "9    NEUTRAL  0.063275  0.864014  0.072712  0.000000      0.000000  0.063975   \n",
      "10   NEUTRAL  0.099986  0.766955  0.133059  0.000000      0.000000  0.037822   \n",
      "11  POSITIVE  0.242612  0.576722  0.180666  0.433333      0.433333  0.849429   \n",
      "12  POSITIVE  0.094545  0.645744  0.259711  0.400000      0.400000  0.047478   \n",
      "13  POSITIVE  0.001688  0.057683  0.940629  0.875000      0.875000  0.038760   \n",
      "\n",
      "         joy  optimism   sadness  \n",
      "0   0.066200  0.072387  0.229975  \n",
      "1   0.066200  0.072387  0.229975  \n",
      "2   0.066200  0.072387  0.229975  \n",
      "3   0.022280  0.859603  0.028587  \n",
      "4   0.795283  0.055113  0.049183  \n",
      "5   0.016022  0.010923  0.878176  \n",
      "6   0.718807  0.135179  0.101759  \n",
      "7   0.920044  0.016402  0.041170  \n",
      "8   0.689981  0.159307  0.086737  \n",
      "9   0.689981  0.159307  0.086737  \n",
      "10  0.909711  0.033201  0.019266  \n",
      "11  0.007850  0.098295  0.044426  \n",
      "12  0.910768  0.024039  0.017715  \n",
      "13  0.718883  0.216383  0.025974  \n",
      "Data Split done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHREESHA\\AppData\\Local\\Temp/ipykernel_14860/3726430549.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emotion_df['Emotion'][i] = 'anger'\n",
      "C:\\Users\\SHREESHA\\AppData\\Local\\Temp/ipykernel_14860/3726430549.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emotion_df['Emotion'][i]= 'optimism'\n",
      "C:\\Users\\SHREESHA\\AppData\\Local\\Temp/ipykernel_14860/3726430549.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emotion_df['Emotion'][i]= 'joy'\n",
      "C:\\Users\\SHREESHA\\AppData\\Local\\Temp/ipykernel_14860/3726430549.py:170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emotion_df['Emotion'][i] = 'sadness'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectoriser fitted.\n",
      "No. of feature_words:  209\n",
      "Data Transformed.\n",
      "\n",
      "\n",
      "Bernoulli Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         joy       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1]]\n",
      "Accuracy Score: \n",
      " 1.0\n",
      "\n",
      "\n",
      "KNN Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00       0.0\n",
      "         joy       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n",
      "Confusion Matrix: \n",
      " [[0 0]\n",
      " [1 0]]\n",
      "Accuracy Score: \n",
      " 0.0\n",
      "\n",
      "\n",
      "Decision Tree Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         joy       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1]]\n",
      "Accuracy Score: \n",
      " 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHREESHA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SHREESHA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SHREESHA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SHREESHA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SHREESHA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SHREESHA\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import tweepy\n",
    "import configparser\n",
    "import datetime\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "api_key = 'rgGB64oTvU6WMCFNX7Pyxue5r'\n",
    "api_key_secret = 'yGhVDdCWIVhps9IhAofymshhIbQuC9gmwAR86mQXk7dWiWl42X'\n",
    "\n",
    "access_token = '1520724296070758400-M1OCv9vcaELtojfbHZDDJRhLmODtQG'\n",
    "access_token_secret = 'RjRAZf7YdvNOypq7yG0673l1S2N5IWIRks2pmgKgqLMiv'\n",
    "\n",
    "# authentication\n",
    "auth_handler = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth_handler.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth_handler)\n",
    "\n",
    "start_date = datetime.datetime(2022, 4, 14)\n",
    "end_date = datetime.datetime(2022, 4, 20)\n",
    "term=\"twittersold\"\n",
    "limit=100\n",
    "public_tweets = tweepy.Cursor(api.search_tweets,q=term).items(limit)\n",
    "\n",
    "polarity = 0.0\n",
    "positive = 0.0\n",
    "negative = 0.0\n",
    "neutral = 0.0\n",
    "# create dataframe\n",
    "columns = ['User', 'Tweet', 'class']\n",
    "data = []\n",
    "\n",
    "for tweet in public_tweets:\n",
    "    analysis = TextBlob(tweet.text) \n",
    "    tweet_polarity = analysis.polarity \n",
    "    if tweet_polarity > 0:\n",
    "        positive += 1 \n",
    "        data.append([tweet.user.screen_name, tweet.text,'POSITIVE'])\n",
    "        #print('pos')\n",
    "    elif tweet_polarity < 0 :\n",
    "        negative +=1\n",
    "        data.append([tweet.user.screen_name, tweet.text,'NEGATIVE'])\n",
    "        #print('neg')\n",
    "    else:\n",
    "        neutral +=1\n",
    "        data.append([tweet.user.screen_name, tweet.text,'NEUTRAL'])\n",
    "        #print('neu')\n",
    "    polarity += analysis.polarity\n",
    "\n",
    "print(polarity)\n",
    "print(f'Amount of Positive tweets: {positive}')\n",
    "print(f'Amount of Negative tweets: {negative}')\n",
    "print(f'Amount of Neutral tweets: {neutral}')\n",
    "\n",
    "\n",
    "tw_list= pd.DataFrame(data, columns=columns)\n",
    "#Cleaning Text (RT, Punctuation etc)\n",
    "#Creating new dataframe and new features\n",
    "#tw_list['Tweet'] = tw_list[0]\n",
    "#Removing RT, Punctuation etc\n",
    "remove_rt = lambda x: re.sub('RT @[\\w]*: ',\" \",x)\n",
    "rt = lambda x: re.sub(\"(@[A-Za-z0‚Äì9]+)|(\\w+:\\/\\/\\S+)\",\" \",x)\n",
    "tw_list['Tweet'] = tw_list.Tweet.map(remove_rt).map(rt)\n",
    "tw_list['Tweet'] = tw_list.Tweet.str.lower()\n",
    "tw_list.to_csv('tweets3.csv') \n",
    "\n",
    "import torch\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\").to(device)\n",
    "import urllib\n",
    "import csv\n",
    "import numpy as np\n",
    "labels=[]\n",
    "task = 'sentiment'\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "print(labels)\n",
    "\n",
    "from scipy.special import softmax\n",
    "BATCH_SIZE = 10\n",
    "sentiment_df=tw_list\n",
    "scores_all = np.empty((0,len(labels)))\n",
    "text_all = sentiment_df['Tweet'].to_list()\n",
    "n = len(text_all)\n",
    "with torch.no_grad():\n",
    "    for start_idx in range(0, n, BATCH_SIZE):\n",
    "        end_idx = min(start_idx+BATCH_SIZE, n)\n",
    "        encoded_input = tokenizer(text_all[start_idx:end_idx], return_tensors='pt', padding=True, max_length=512,truncation=True).to(device)\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0].detach().cpu().numpy()\n",
    "        scores = softmax(scores, axis=1)\n",
    "        scores_all = np.concatenate((scores_all, scores), axis=0)\n",
    "        del encoded_input, output, scores\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "sentiment_df[labels] = pd.DataFrame(scores_all, columns=labels)\n",
    "#print(sentiment_df)\n",
    "\n",
    "from textblob import TextBlob\n",
    "def get_sentiment(tweet):\n",
    "    sentiment = TextBlob(tweet).sentiment\n",
    "    return sentiment.polarity, sentiment.subjectivity\n",
    "\n",
    "sentiment_df['sentiment'] = sentiment_df['Tweet'].apply(get_sentiment)\n",
    "sentiment_df['polarity'] = sentiment_df['sentiment'].apply(lambda x:x[0])\n",
    "sentiment_df['subjectivity'] = sentiment_df['sentiment'].apply(lambda x:x[0])\n",
    "sentiment_df.drop('sentiment', axis=1, inplace=True)\n",
    "\n",
    "emotion_tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n",
    "emotion_model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\").to(device)\n",
    "task='emotion'\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "scores_all = np.empty((0,len(labels)))\n",
    "text_all = sentiment_df['Tweet'].to_list()\n",
    "n = len(text_all)\n",
    "with torch.no_grad():\n",
    "    for start_idx in range(0, n, BATCH_SIZE):\n",
    "        end_idx = min(start_idx+BATCH_SIZE, n)\n",
    "        encoded_input = tokenizer(text_all[start_idx:end_idx], return_tensors='pt', padding=True, max_length=512,truncation=True).to(device)\n",
    "        output = emotion_model(**encoded_input)\n",
    "        scores = output[0].detach().cpu().numpy()\n",
    "        scores = softmax(scores, axis=1)\n",
    "        scores_all = np.concatenate((scores_all, scores), axis=0)\n",
    "        del encoded_input, output, scores\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "sentiment_df[labels] = pd.DataFrame(scores_all, columns=labels)\n",
    "#print(sentiment_df)\n",
    "emotion_df=sentiment_df\n",
    "emotion_df.drop(['negative','positive','neutral','polarity','subjectivity'], axis=1, inplace=True)\n",
    "emotion_df.insert(7, \"Emotion\", '')\n",
    "for i in range(len(emotion_df)):\n",
    "  if emotion_df['anger'][i] > emotion_df['joy'][i] and emotion_df['anger'][i] > emotion_df['optimism'][i] and emotion_df['anger'][i] > emotion_df['sadness'][i]:\n",
    "    emotion_df['Emotion'][i] = 'anger'\n",
    "  elif emotion_df['joy'][i] > emotion_df['anger'][i] and emotion_df['joy'][i] > emotion_df['optimism'][i] and emotion_df['joy'][i] > emotion_df['sadness'][i]:\n",
    "    emotion_df['Emotion'][i]= 'joy'\n",
    "  elif emotion_df['optimism'][i] > emotion_df['anger'][i] and emotion_df['optimism'][i] > emotion_df['joy'][i] and emotion_df['optimism'][i] > emotion_df['sadness'][i]:\n",
    "    emotion_df['Emotion'][i]= 'optimism'\n",
    "  else:\n",
    "    emotion_df['Emotion'][i] = 'sadness'\n",
    "\n",
    "emotion_df.drop(['anger','joy','optimism','sadness'], axis=1, inplace=True)\n",
    "#graph\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize = (8,7))\n",
    "sns.countplot(x=\"Emotion\", data=emotion_df, palette='magma')\n",
    "\n",
    "def preprocess(textdata):\n",
    "    processedText = []\n",
    "    # Create Lemmatizer and Stemmer.\n",
    "    wordLemm = WordNetLemmatizer()\n",
    "    for tweet in textdata:\n",
    "        tweetwords = ''\n",
    "        for word in tweet.split():\n",
    "             # Checking if the word is a stopword.\n",
    "             #if word not in stopwordlist:\n",
    "             if len(word)>1:\n",
    "                # Lemmatizing the word.\n",
    "                word = wordLemm.lemmatize(word)\n",
    "                tweetwords += (word+' ')\n",
    "            \n",
    "        processedText.append(tweetwords)\n",
    "        \n",
    "    return processedText\n",
    "\n",
    "#Accuracy and Confusion Matrix\n",
    "processedtext = preprocess(emotion_df['Tweet'])\n",
    "dataset = emotion_df[['Emotion','Tweet']]\n",
    "text, emotion = list(dataset['Tweet']), list(dataset['Emotion'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(processedtext, emotion,test_size = 0.05, random_state = 0)\n",
    "print(f'Data Split done.')\n",
    "vectoriser = TfidfVectorizer(ngram_range=(1,2), max_features=500000)\n",
    "vectoriser.fit(X_train)\n",
    "print(f'Vectoriser fitted.')\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)\n",
    "print(f'Data Transformed.')\n",
    "\n",
    "#EVALUATION\n",
    "    #Bernoulli\n",
    "BNBmodel = BernoulliNB(alpha = 2)\n",
    "BNBmodel.fit(X_train, y_train)\n",
    "ys_predict = BNBmodel.predict(X_test)\n",
    "#Display the outcome of classification\n",
    "print('\\n\\nBernoulli Classification Report: \\n',metrics.classification_report(y_test, ys_predict))\n",
    "print('Confusion Matrix: \\n',metrics.confusion_matrix(y_test, ys_predict))\n",
    "print('Accuracy Score: \\n',metrics.accuracy_score(y_test, ys_predict))\n",
    "\n",
    "    #KNN\n",
    "KNNModel = KNeighborsClassifier(n_neighbors=5)\n",
    "KNNModel.fit(X_train, y_train)\n",
    "ys_predict = KNNModel.predict(X_test)\n",
    "#Display the outcome of classification\n",
    "print('\\n\\nKNN Classification Report: \\n',metrics.classification_report(y_test, ys_predict))\n",
    "print('Confusion Matrix: \\n',metrics.confusion_matrix(y_test, ys_predict))\n",
    "print('Accuracy Score: \\n',metrics.accuracy_score(y_test, ys_predict))\n",
    "\n",
    "    #Decision Tree\n",
    "DTCModel = DecisionTreeClassifier(random_state=0)\n",
    "DTCModel.fit(X_train, y_train)\n",
    "ys_predict = DTCModel.predict(X_test)\n",
    "#Display the outcome of classification\n",
    "print('\\n\\nDecision Tree Classification Report: \\n',metrics.classification_report(y_test, ys_predict))\n",
    "print('Confusion Matrix: \\n',metrics.confusion_matrix(y_test, ys_predict))\n",
    "print('Accuracy Score: \\n',metrics.accuracy_score(y_test, ys_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9fb82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3624a12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304538a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
